steps:
  - label: "benchmark_master"
    parallelism: 1
    command: bash .buildkite/scripts/benchmark_master.sh
    env:
      MASTER_ADDR: "10.158.66.134"
      MASTER_PORT: "29500"
    plugins:
      - docker#v5.3.0:
          image: "baguasys/bagua:master-pytorch-1.13.0-cuda11.6-cudnn8"
          workdir: /upstream
          user: root
          propagate-environment: true
          runtime: nvidia
          network: host
          ipc: host
          shm-size: 100gb
          always-pull: true
          publish: [ "8001:8001", "29500:29500" ]
    agents:
      queue: "master"
  - label: "benchmark_worker"
    parallelism: 1
    command: bash .buildkite/scripts/benchmark_worker.sh
    env:
      MASTER_ADDR: "10.158.66.134"
      MASTER_PORT: "29500"
    plugins:
      - docker#v5.3.0:
          image: "baguasys/bagua:master-pytorch-1.13.0-cuda11.6-cudnn8"
          workdir: /upstream
          user: root
          propagate-environment: true
          runtime: nvidia
          network: host
          ipc: host
          shm-size: 100gb
          always-pull: true
  - label: "autotune_test"
    parallelism: 1
    command: bash .buildkite/scripts/benchmark.sh
    plugins:
      - docker#v5.3.0:
          image: "baguasys/bagua:master-pytorch-1.13.0-cuda11.6-cudnn8"
          workdir: /upstream
          user: root
          propagate-environment: true
          runtime: nvidia
          network: host
          ipc: host
          shm-size: 100gb
          always-pull: true
  - label: "pytest"
    parallelism: 1
    command: bash .buildkite/scripts/run_pytest.sh
    plugins:
      - docker#v5.3.0:
          image: "baguasys/bagua:master-pytorch-1.13.0-cuda11.6-cudnn8"
          workdir: /upstream
          user: root
          propagate-environment: true
          runtime: nvidia
          network: host
          ipc: host
          shm-size: 100gb
          always-pull: true
